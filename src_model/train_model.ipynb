{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (2.1.4)\n",
      "Requirement already satisfied: tensorflow in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: keras in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (3.11.3)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas tensorflow keras os numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiá»ƒm tra GPU...\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "âœ“ Äang sá»­ dá»¥ng GPU\n",
      "\n",
      "================================================================================\n",
      "                    URL CLASSIFIER - TRAINING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š BÆ¯á»šC 1: LOAD Dá»® LIá»†U\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ“ Äang Ä‘á»c file URL sáº¡ch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Äá»c benign.txt: 6012821it [00:01, 4145059.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Äang Ä‘á»c file URL Ä‘á»™c háº¡i...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Äá»c malicious.txt: 3524939it [00:00, 4160118.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ÄÃ£ loáº¡i bá» 39896 URL trÃ¹ng láº·p\n",
      "\n",
      "âœ“ Tá»•ng sá»‘ URL: 9,497,864\n",
      "  - URL Sáº¡ch (0): 6,012,821\n",
      "  - URL Äá»™c háº¡i (1): 3,485,043\n",
      "\n",
      "âš–ï¸ BÆ¯á»šC 2: CÃ‚N Báº°NG Dá»® LIá»†U\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ Sá»­ dá»¥ng 2,788,034 máº«u/loáº¡i cho Train+Val\n",
      "âœ“ Sá»­ dá»¥ng 697,009 máº«u/loáº¡i cho Test\n",
      "\n",
      "âœ“ Train/Val: 5,576,068 samples\n",
      "âœ“ Test: 1,394,018 samples\n",
      "\n",
      "ğŸ”§ BÆ¯á»šC 3: TIá»€N Xá»¬ LÃ Dá»® LIá»†U\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xá»­ lÃ½ Train/Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5576068/5576068 [00:11<00:00, 478675.69it/s]\n",
      "Xá»­ lÃ½ Test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1394018/1394018 [00:02<00:00, 486410.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ‚ï¸ BÆ¯á»šC 4: CHIA TRAIN/VALIDATION\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ Train: 4,460,854 samples\n",
      "âœ“ Validation: 1,115,214 samples\n",
      "âœ“ Test: 1,394,018 samples\n",
      "\n",
      "ğŸ—ï¸ BÆ¯á»šC 5: XÃ‚Y Dá»°NG MÃ” HÃŒNH\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ“ Äang adapt TextVectorization layer...\n",
      "âœ“ Adapt hoÃ n táº¥t\n",
      "\n",
      "ğŸ“‹ Kiáº¿n trÃºc mÃ´ hÃ¬nh:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_url           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ text_vectorizationâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_url[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>) â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_1         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ text_vectorizatiâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_1 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">57,472</span> â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_poolingâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1â€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> â”‚ global_max_pooliâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_url           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ text_vectorizationâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_url[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mTextVectorization\u001b[0m) â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_1         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚      \u001b[38;5;34m8,192\u001b[0m â”‚ text_vectorizatiâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_1 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”‚ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚     \u001b[38;5;34m24,704\u001b[0m â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚     \u001b[38;5;34m41,088\u001b[0m â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚     \u001b[38;5;34m57,472\u001b[0m â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m384\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_poolingâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ concatenate_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalMaxPooling1â€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m98,560\u001b[0m â”‚ global_max_pooliâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚        \u001b[38;5;34m129\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,113</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,113\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">264,577</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m264,577\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš™ï¸ BÆ¯á»šC 6: CÃ€I Äáº¶T CALLBACKS\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ EarlyStopping (patience=3)\n",
      "âœ“ ReduceLROnPlateau (factor=0.5, patience=2)\n",
      "âœ“ ModelCheckpoint (save best model)\n",
      "\n",
      "âœ“ Class Weights: {0: 1.0, 1: 1.0}\n",
      "\n",
      "ğŸš€ BÆ¯á»šC 7: HUáº¤N LUYá»†N MÃ” HÃŒNH\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ Epochs: 20\n",
      "âœ“ Batch Size: 512\n",
      "\n",
      "Báº¯t Ä‘áº§u training...\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9613 - loss: 0.1100 - precision: 0.9727 - recall: 0.9493\n",
      "Epoch 1: val_accuracy improved from None to 0.97732, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 53ms/step - accuracy: 0.9691 - loss: 0.0928 - precision: 0.9797 - recall: 0.9581 - val_accuracy: 0.9773 - val_loss: 0.0730 - val_precision: 0.9872 - val_recall: 0.9672 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9753 - loss: 0.0780 - precision: 0.9845 - recall: 0.9658\n",
      "Epoch 2: val_accuracy did not improve from 0.97732\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 53ms/step - accuracy: 0.9756 - loss: 0.0770 - precision: 0.9847 - recall: 0.9662 - val_accuracy: 0.9759 - val_loss: 0.0750 - val_precision: 0.9945 - val_recall: 0.9571 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9772 - loss: 0.0731 - precision: 0.9858 - recall: 0.9683\n",
      "Epoch 3: val_accuracy improved from 0.97732 to 0.97882, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 52ms/step - accuracy: 0.9773 - loss: 0.0725 - precision: 0.9859 - recall: 0.9685 - val_accuracy: 0.9788 - val_loss: 0.0672 - val_precision: 0.9931 - val_recall: 0.9644 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9783 - loss: 0.0700 - precision: 0.9867 - recall: 0.9696\n",
      "Epoch 4: val_accuracy improved from 0.97882 to 0.98040, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 53ms/step - accuracy: 0.9783 - loss: 0.0699 - precision: 0.9868 - recall: 0.9697 - val_accuracy: 0.9804 - val_loss: 0.0632 - val_precision: 0.9864 - val_recall: 0.9742 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9790 - loss: 0.0681 - precision: 0.9871 - recall: 0.9706\n",
      "Epoch 5: val_accuracy improved from 0.98040 to 0.98062, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 53ms/step - accuracy: 0.9790 - loss: 0.0681 - precision: 0.9872 - recall: 0.9706 - val_accuracy: 0.9806 - val_loss: 0.0638 - val_precision: 0.9914 - val_recall: 0.9696 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9795 - loss: 0.0667 - precision: 0.9876 - recall: 0.9711\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.98062\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 53ms/step - accuracy: 0.9794 - loss: 0.0668 - precision: 0.9876 - recall: 0.9711 - val_accuracy: 0.9806 - val_loss: 0.0633 - val_precision: 0.9924 - val_recall: 0.9686 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9806 - loss: 0.0638 - precision: 0.9885 - recall: 0.9726\n",
      "Epoch 7: val_accuracy improved from 0.98062 to 0.98101, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 53ms/step - accuracy: 0.9807 - loss: 0.0635 - precision: 0.9886 - recall: 0.9726 - val_accuracy: 0.9810 - val_loss: 0.0626 - val_precision: 0.9935 - val_recall: 0.9683 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9810 - loss: 0.0626 - precision: 0.9888 - recall: 0.9730\n",
      "Epoch 8: val_accuracy improved from 0.98101 to 0.98139, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 53ms/step - accuracy: 0.9810 - loss: 0.0626 - precision: 0.9888 - recall: 0.9730 - val_accuracy: 0.9814 - val_loss: 0.0609 - val_precision: 0.9931 - val_recall: 0.9695 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9811 - loss: 0.0622 - precision: 0.9890 - recall: 0.9730\n",
      "Epoch 9: val_accuracy improved from 0.98139 to 0.98169, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 53ms/step - accuracy: 0.9811 - loss: 0.0620 - precision: 0.9889 - recall: 0.9732 - val_accuracy: 0.9817 - val_loss: 0.0602 - val_precision: 0.9925 - val_recall: 0.9707 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9813 - loss: 0.0615 - precision: 0.9890 - recall: 0.9733\n",
      "Epoch 10: val_accuracy improved from 0.98169 to 0.98178, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 53ms/step - accuracy: 0.9812 - loss: 0.0616 - precision: 0.9890 - recall: 0.9733 - val_accuracy: 0.9818 - val_loss: 0.0601 - val_precision: 0.9928 - val_recall: 0.9706 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9814 - loss: 0.0609 - precision: 0.9891 - recall: 0.9736\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.98178\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 53ms/step - accuracy: 0.9814 - loss: 0.0612 - precision: 0.9891 - recall: 0.9735 - val_accuracy: 0.9816 - val_loss: 0.0616 - val_precision: 0.9933 - val_recall: 0.9697 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9820 - loss: 0.0594 - precision: 0.9896 - recall: 0.9743\n",
      "Epoch 12: val_accuracy improved from 0.98178 to 0.98207, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 53ms/step - accuracy: 0.9820 - loss: 0.0595 - precision: 0.9896 - recall: 0.9743 - val_accuracy: 0.9821 - val_loss: 0.0590 - val_precision: 0.9930 - val_recall: 0.9710 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9822 - loss: 0.0590 - precision: 0.9897 - recall: 0.9745\n",
      "Epoch 13: val_accuracy improved from 0.98207 to 0.98230, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 53ms/step - accuracy: 0.9821 - loss: 0.0592 - precision: 0.9896 - recall: 0.9744 - val_accuracy: 0.9823 - val_loss: 0.0589 - val_precision: 0.9921 - val_recall: 0.9723 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9823 - loss: 0.0586 - precision: 0.9898 - recall: 0.9746\n",
      "Epoch 14: val_accuracy improved from 0.98230 to 0.98249, saving model to best_modelsaved.keras\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 53ms/step - accuracy: 0.9823 - loss: 0.0588 - precision: 0.9898 - recall: 0.9746 - val_accuracy: 0.9825 - val_loss: 0.0582 - val_precision: 0.9916 - val_recall: 0.9732 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9822 - loss: 0.0586 - precision: 0.9897 - recall: 0.9746\n",
      "Epoch 15: val_accuracy did not improve from 0.98249\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 53ms/step - accuracy: 0.9823 - loss: 0.0587 - precision: 0.9898 - recall: 0.9746 - val_accuracy: 0.9824 - val_loss: 0.0590 - val_precision: 0.9929 - val_recall: 0.9717 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m8712/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9824 - loss: 0.0584 - precision: 0.9899 - recall: 0.9747\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.98249\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 53ms/step - accuracy: 0.9823 - loss: 0.0585 - precision: 0.9898 - recall: 0.9746 - val_accuracy: 0.9824 - val_loss: 0.0587 - val_precision: 0.9924 - val_recall: 0.9723 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9826 - loss: 0.0578 - precision: 0.9900 - recall: 0.9750\n",
      "Epoch 17: val_accuracy did not improve from 0.98249\n",
      "\u001b[1m8713/8713\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 53ms/step - accuracy: 0.9825 - loss: 0.0578 - precision: 0.9900 - recall: 0.9750 - val_accuracy: 0.9825 - val_loss: 0.0584 - val_precision: 0.9925 - val_recall: 0.9723 - learning_rate: 1.2500e-04\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\n",
      "âœ“ Training hoÃ n táº¥t!\n",
      "\n",
      "ğŸ“Š BÆ¯á»šC 8: Váº¼ BIá»‚U Äá»’\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ training táº¡i: training_history.png\n",
      "\n",
      "ğŸ’¾ BÆ¯á»šC 9: LÆ¯U MÃ” HÃŒNH\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ ÄÃ£ lÆ°u model (dáº¡ng file Keras) táº¡i: url_classifier_model.keras\n",
      "\n",
      "ğŸ¯ BÆ¯á»šC 10: ÄÃNH GIÃ TRÃŠN Táº¬P TEST\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Äang Ä‘Ã¡nh giÃ¡...\n",
      "\n",
      "ğŸ“ˆ Káº¿t quáº£ trÃªn táº­p Test:\n",
      "  - Loss: 0.0582\n",
      "  - Accuracy: 98.26%\n",
      "  - Precision: 99.17%\n",
      "  - Recall: 97.34%\n",
      "\n",
      "Äang táº¡o dá»± Ä‘oÃ¡n cho bÃ¡o cÃ¡o chi tiáº¿t...\n",
      "\n",
      "ğŸ“‹ Classification Report:\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Sáº¡ch (0)     0.9739    0.9918    0.9828    697009\n",
      " Äá»™c háº¡i (1)     0.9917    0.9734    0.9825    697009\n",
      "\n",
      "    accuracy                         0.9826   1394018\n",
      "   macro avg     0.9828    0.9826    0.9826   1394018\n",
      "weighted avg     0.9828    0.9826    0.9826   1394018\n",
      "\n",
      "âœ“ ÄÃ£ lÆ°u confusion matrix táº¡i: confusion_matrix.png\n",
      "\n",
      "================================================================================\n",
      "âœ… HOÃ€N THÃ€NH! MÃ´ hÃ¬nh Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng.\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Files Ä‘Ã£ táº¡o:\n",
      "  - url_classifier_model.keras (mÃ´ hÃ¬nh chÃ­nh)\n",
      "  - best_model.h5 (mÃ´ hÃ¬nh tá»‘t nháº¥t)\n",
      "  - training_history.png (biá»ƒu Ä‘á»“ training)\n",
      "  - confusion_matrix.png (ma tráº­n nháº§m láº«n)\n",
      "\n",
      "ğŸ’¡ Äá»ƒ test mÃ´ hÃ¬nh, sá»­ dá»¥ng file test script vá»›i model nÃ y!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, \n",
    "    TextVectorization, BatchNormalization, SpatialDropout1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Táº¯t warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sá»­ dá»¥ng GPU náº¿u cÃ³\n",
    "print(\"Kiá»ƒm tra GPU...\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"âœ“ Äang sá»­ dá»¥ng GPU\")\n",
    "else:\n",
    "    print(\"âš  Äang sá»­ dá»¥ng CPU\")\n",
    "\n",
    "# --- 1. Táº£i dá»¯ liá»‡u ---\n",
    "def load_data_from_txt(good_file, bad_file):\n",
    "    \"\"\"Táº£i dá»¯ liá»‡u tá»« file txt\"\"\"\n",
    "    good_urls = []\n",
    "    print(\"\\nğŸ“ Äang Ä‘á»c file URL sáº¡ch...\")\n",
    "    with open(good_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in tqdm(f, desc=f\"Äá»c {good_file}\"):\n",
    "            url = line.strip()\n",
    "            if url:  # Bá» qua dÃ²ng trá»‘ng\n",
    "                good_urls.append(url)\n",
    "\n",
    "    bad_urls = []\n",
    "    print(\"\\nğŸ“ Äang Ä‘á»c file URL Ä‘á»™c háº¡i...\")\n",
    "    with open(bad_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in tqdm(f, desc=f\"Äá»c {bad_file}\"):\n",
    "            url = line.strip()\n",
    "            if url:  # Bá» qua dÃ²ng trá»‘ng\n",
    "                bad_urls.append(url)\n",
    "\n",
    "    df_good = pd.DataFrame({'url': good_urls, 'label': 0})\n",
    "    df_bad = pd.DataFrame({'url': bad_urls, 'label': 1})\n",
    "\n",
    "    df = pd.concat([df_good, df_bad], ignore_index=True)\n",
    "    \n",
    "    # Loáº¡i bá» duplicate\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=['url'])\n",
    "    after = len(df)\n",
    "    if before != after:\n",
    "        print(f\"âœ“ ÄÃ£ loáº¡i bá» {before - after} URL trÃ¹ng láº·p\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- 2. Tiá»n xá»­ lÃ½ ---\n",
    "def preprocess_url_for_keras(url):\n",
    "    \"\"\"\n",
    "    Tiá»n xá»­ lÃ½ URL cho mÃ´ hÃ¬nh Keras.\n",
    "    TÃ¡ch má»—i kÃ½ tá»± báº±ng dáº¥u cÃ¡ch Ä‘á»ƒ TextVectorization xá»­ lÃ½ tá»«ng kÃ½ tá»±.\n",
    "    \"\"\"\n",
    "    # Chuyá»ƒn vá» lowercase\n",
    "    url = url.lower()\n",
    "    # XÃ³a http://, https://, www.\n",
    "    url = re.sub(r'https?://|www\\.', '', url)\n",
    "    # Giá»›i háº¡n Ä‘á»™ dÃ i (trÃ¡nh URL quÃ¡ dÃ i)\n",
    "    url = url[:500]\n",
    "    # TÃ¡ch má»i kÃ½ tá»± báº±ng dáº¥u cÃ¡ch\n",
    "    url = \" \".join(list(url))\n",
    "    return url\n",
    "\n",
    "# --- 3. XÃ¢y dá»±ng mÃ´ hÃ¬nh CNN tá»‘i Æ°u ---\n",
    "def build_optimized_model(vocab_size=128, max_len=200, embedding_dim=64):\n",
    "    \"\"\"\n",
    "    XÃ¢y dá»±ng mÃ´ hÃ¬nh CNN 1D tá»‘i Æ°u vá»›i:\n",
    "    - Batch Normalization\n",
    "    - Multiple Conv layers\n",
    "    - Spatial Dropout\n",
    "    - Better regularization\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(1,), dtype=tf.string, name='input_url')\n",
    "    \n",
    "    # TextVectorization layer (sáº½ Ä‘Æ°á»£c adapt sau)\n",
    "    vectorize_layer = TextVectorization(\n",
    "        max_tokens=vocab_size,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=max_len\n",
    "    )\n",
    "    \n",
    "    # Embedding layer\n",
    "    x = vectorize_layer(input_layer)\n",
    "    x = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=max_len,\n",
    "        mask_zero=True  # Há»— trá»£ padding\n",
    "    )(x)\n",
    "    \n",
    "    # Spatial Dropout (tá»‘t hÆ¡n cho embedding)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    \n",
    "    # Multiple Conv1D layers vá»›i kernel sizes khÃ¡c nhau\n",
    "    conv1 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    conv2 = Conv1D(filters=128, kernel_size=5, activation='relu', padding='same')(x)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    conv3 = Conv1D(filters=128, kernel_size=7, activation='relu', padding='same')(x)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    # Concatenate cÃ¡c conv layers\n",
    "    x = tf.keras.layers.Concatenate()([conv1, conv2, conv3])\n",
    "    \n",
    "    # Global pooling\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output_layer = Dense(1, activation='sigmoid', name='output')(x)\n",
    "    \n",
    "    # Táº¡o model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model, vectorize_layer\n",
    "\n",
    "# --- 4. Váº½ biá»ƒu Ä‘á»“ training history ---\n",
    "def plot_training_history(history, save_path='training_history.png'):\n",
    "    \"\"\"Váº½ biá»ƒu Ä‘á»“ loss vÃ  accuracy\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "    axes[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axes[0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    axes[1].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    axes[1].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"âœ“ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ training táº¡i: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# --- 5. Váº½ confusion matrix ---\n",
    "def plot_confusion_matrix(y_true, y_pred, save_path='confusion_matrix.png'):\n",
    "    \"\"\"Váº½ confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Sáº¡ch', 'Äá»™c háº¡i'],\n",
    "                yticklabels=['Sáº¡ch', 'Äá»™c háº¡i'])\n",
    "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"âœ“ ÄÃ£ lÆ°u confusion matrix táº¡i: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# --- 6. HÃ m chÃ­nh ---\n",
    "def main_process_and_train_keras():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" \"*20 + \"URL CLASSIFIER - TRAINING PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # --- Táº£i dá»¯ liá»‡u ---\n",
    "    print(\"\\nğŸ“Š BÆ¯á»šC 1: LOAD Dá»® LIá»†U\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    try:\n",
    "        df = load_data_from_txt('benign.txt', 'malicious.txt')\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file - {e}\")\n",
    "        return\n",
    "\n",
    "    df_good = df[df['label'] == 0]\n",
    "    df_bad = df[df['label'] == 1]\n",
    "    \n",
    "    print(f\"\\nâœ“ Tá»•ng sá»‘ URL: {len(df):,}\")\n",
    "    print(f\"  - URL Sáº¡ch (0): {len(df_good):,}\")\n",
    "    print(f\"  - URL Äá»™c háº¡i (1): {len(df_bad):,}\")\n",
    "    \n",
    "    # --- CÃ¢n báº±ng dá»¯ liá»‡u ---\n",
    "    print(\"\\nâš–ï¸ BÆ¯á»šC 2: CÃ‚N Báº°NG Dá»® LIá»†U\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh N_SAMPLES\n",
    "    N_SAMPLES = min(len(df_good), len(df_bad))\n",
    "    \n",
    "    # Äá»ƒ láº¡i 20% cho test\n",
    "    train_val_size = int(N_SAMPLES * 0.8)\n",
    "    test_size = N_SAMPLES - train_val_size\n",
    "    \n",
    "    print(f\"âœ“ Sá»­ dá»¥ng {train_val_size:,} máº«u/loáº¡i cho Train+Val\")\n",
    "    print(f\"âœ“ Sá»­ dá»¥ng {test_size:,} máº«u/loáº¡i cho Test\")\n",
    "    \n",
    "    # Chia dá»¯ liá»‡u\n",
    "    good_train_val = df_good.sample(n=train_val_size, random_state=42)\n",
    "    bad_train_val = df_bad.sample(n=train_val_size, random_state=42)\n",
    "    \n",
    "    good_test = df_good.drop(good_train_val.index).sample(n=test_size, random_state=42)\n",
    "    bad_test = df_bad.drop(bad_train_val.index).sample(n=test_size, random_state=42)\n",
    "    \n",
    "    df_train_val = pd.concat([good_train_val, bad_train_val]).sample(frac=1, random_state=42)\n",
    "    df_test = pd.concat([good_test, bad_test]).sample(frac=1, random_state=42)\n",
    "    \n",
    "    print(f\"\\nâœ“ Train/Val: {len(df_train_val):,} samples\")\n",
    "    print(f\"âœ“ Test: {len(df_test):,} samples\")\n",
    "    \n",
    "    # --- Tiá»n xá»­ lÃ½ ---\n",
    "    print(\"\\nğŸ”§ BÆ¯á»šC 3: TIá»€N Xá»¬ LÃ Dá»® LIá»†U\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    tqdm.pandas(desc=\"Xá»­ lÃ½ Train/Val\")\n",
    "    df_train_val['processed_url'] = df_train_val['url'].progress_apply(preprocess_url_for_keras)\n",
    "    \n",
    "    tqdm.pandas(desc=\"Xá»­ lÃ½ Test\")\n",
    "    df_test['processed_url'] = df_test['url'].progress_apply(preprocess_url_for_keras)\n",
    "    \n",
    "    # --- Chia Train/Val ---\n",
    "    print(\"\\nâœ‚ï¸ BÆ¯á»šC 4: CHIA TRAIN/VALIDATION\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    X_tv = df_train_val['processed_url'].values\n",
    "    y_tv = df_train_val['label'].values.astype('float32')\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_tv, y_tv, test_size=0.2, random_state=42, stratify=y_tv\n",
    "    )\n",
    "    \n",
    "    X_test = df_test['processed_url'].values\n",
    "    y_test = df_test['label'].values.astype('float32')\n",
    "    \n",
    "    print(f\"âœ“ Train: {len(X_train):,} samples\")\n",
    "    print(f\"âœ“ Validation: {len(X_val):,} samples\")\n",
    "    print(f\"âœ“ Test: {len(X_test):,} samples\")\n",
    "    \n",
    "    # --- XÃ¢y dá»±ng Model ---\n",
    "    print(\"\\nğŸ—ï¸ BÆ¯á»šC 5: XÃ‚Y Dá»°NG MÃ” HÃŒNH\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    MAX_LEN = 200\n",
    "    VOCAB_SIZE = 128\n",
    "    EMBEDDING_DIM = 64\n",
    "    \n",
    "    model, vectorize_layer = build_optimized_model(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        max_len=MAX_LEN,\n",
    "        embedding_dim=EMBEDDING_DIM\n",
    "    )\n",
    "    \n",
    "    # Adapt vectorization layer\n",
    "    print(\"\\nâœ“ Äang adapt TextVectorization layer...\")\n",
    "    vectorize_layer.adapt(X_train)\n",
    "    print(\"âœ“ Adapt hoÃ n táº¥t\")\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', \n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Kiáº¿n trÃºc mÃ´ hÃ¬nh:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # --- Callbacks ---\n",
    "    print(\"\\nâš™ï¸ BÆ¯á»šC 6: CÃ€I Äáº¶T CALLBACKS\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            'best_modelsaved.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"âœ“ EarlyStopping (patience=3)\")\n",
    "    print(\"âœ“ ReduceLROnPlateau (factor=0.5, patience=2)\")\n",
    "    print(\"âœ“ ModelCheckpoint (save best model)\")\n",
    "    \n",
    "    # --- TÃ­nh Class Weight ---\n",
    "    classes = np.array([0, 1])\n",
    "    class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "    class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "    print(f\"\\nâœ“ Class Weights: {class_weight_dict}\")\n",
    "    \n",
    "    # --- Training ---\n",
    "    print(\"\\nğŸš€ BÆ¯á»šC 7: HUáº¤N LUYá»†N MÃ” HÃŒNH\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    N_EPOCHS = 20\n",
    "    BATCH_SIZE = 512  # Tá»‘i Æ°u cho cáº£ CPU vÃ  GPU\n",
    "    \n",
    "    print(f\"âœ“ Epochs: {N_EPOCHS}\")\n",
    "    print(f\"âœ“ Batch Size: {BATCH_SIZE}\")\n",
    "    print(\"\\nBáº¯t Ä‘áº§u training...\\n\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=N_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val, y_val),\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ“ Training hoÃ n táº¥t!\")\n",
    "    \n",
    "    # --- Váº½ biá»ƒu Ä‘á»“ ---\n",
    "    print(\"\\nğŸ“Š BÆ¯á»šC 8: Váº¼ BIá»‚U Äá»’\")\n",
    "    print(\"-\"*80)\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # --- LÆ°u Model ---\n",
    "    print(\"\\nğŸ’¾ BÆ¯á»šC 9: LÆ¯U MÃ” HÃŒNH\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    MODEL_PATH = 'url_classifier_model.keras'\n",
    "    model.save(MODEL_PATH)\n",
    "    print(f\"âœ“ ÄÃ£ lÆ°u model (dáº¡ng file Keras) táº¡i: {MODEL_PATH}\")\n",
    "    \n",
    "    # --- ÄÃ¡nh giÃ¡ trÃªn Test ---\n",
    "    print(\"\\nğŸ¯ BÆ¯á»šC 10: ÄÃNH GIÃ TRÃŠN Táº¬P TEST\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    print(\"\\nÄang Ä‘Ã¡nh giÃ¡...\")\n",
    "    test_results = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ Káº¿t quáº£ trÃªn táº­p Test:\")\n",
    "    print(f\"  - Loss: {test_results[0]:.4f}\")\n",
    "    print(f\"  - Accuracy: {test_results[1]*100:.2f}%\")\n",
    "    print(f\"  - Precision: {test_results[2]*100:.2f}%\")\n",
    "    print(f\"  - Recall: {test_results[3]*100:.2f}%\")\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nÄang táº¡o dá»± Ä‘oÃ¡n cho bÃ¡o cÃ¡o chi tiáº¿t...\")\n",
    "    y_test_pred_proba = model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "    y_test_pred = (y_test_pred_proba > 0.5).astype(int).flatten()\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Classification Report:\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(\n",
    "        y_test, \n",
    "        y_test_pred, \n",
    "        target_names=['Sáº¡ch (0)', 'Äá»™c háº¡i (1)'],\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plot_confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    # --- HoÃ n thÃ nh ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"âœ… HOÃ€N THÃ€NH! MÃ´ hÃ¬nh Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng.\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nğŸ“ Files Ä‘Ã£ táº¡o:\")\n",
    "    print(f\"  - {MODEL_PATH} (mÃ´ hÃ¬nh chÃ­nh)\")\n",
    "    print(f\"  - best_model.h5 (mÃ´ hÃ¬nh tá»‘t nháº¥t)\")\n",
    "    print(f\"  - training_history.png (biá»ƒu Ä‘á»“ training)\")\n",
    "    print(f\"  - confusion_matrix.png (ma tráº­n nháº§m láº«n)\")\n",
    "    print(\"\\nğŸ’¡ Äá»ƒ test mÃ´ hÃ¬nh, sá»­ dá»¥ng file test script vá»›i model nÃ y!\")\n",
    "\n",
    "# --- Main ---\n",
    "if __name__ == \"__main__\":\n",
    "    main_process_and_train_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 07:53:47.062156: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                    ğŸš€ CODE Cá»¨U Vá»šT - ÄÃNH GIÃ MÃ” HÃŒNH\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¦ BÆ¯á»šC 1: LOAD MODEL\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762761230.506554    2953 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43742 MB memory:  -> device: 0, name: NVIDIA L40S, pci bus id: 0000:34:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÄÃ£ load model tá»«: url_classifier_model.keras\n",
      "âœ“ Model architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_url           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ text_vectorizationâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_url[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>) â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_1         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ text_vectorizatiâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_1 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">57,472</span> â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_poolingâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1â€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> â”‚ global_max_pooliâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_url           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ text_vectorizationâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_url[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mTextVectorization\u001b[0m) â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_1         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚      \u001b[38;5;34m8,192\u001b[0m â”‚ text_vectorizatiâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ spatial_dropout1d_1 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”‚ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚     \u001b[38;5;34m24,704\u001b[0m â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚     \u001b[38;5;34m41,088\u001b[0m â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚     \u001b[38;5;34m57,472\u001b[0m â”‚ spatial_dropout1â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m384\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_poolingâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ concatenate_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalMaxPooling1â€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m98,560\u001b[0m â”‚ global_max_pooliâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚        \u001b[38;5;34m129\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">795,269</span> (3.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m795,269\u001b[0m (3.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">264,577</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m264,577\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">529,156</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m529,156\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š BÆ¯á»šC 2: LOAD Dá»® LIá»†U TEST\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ“ Äang Ä‘á»c benign.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Äá»c URL sáº¡ch: 6012821it [00:01, 4606934.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Äang Ä‘á»c malicious.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Äá»c URL Ä‘á»™c háº¡i: 3524939it [00:00, 3921081.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ÄÃ£ load 1,394,018 samples test\n",
      "   - Sáº¡ch: 697,009\n",
      "   - Äá»™c háº¡i: 697,009\n",
      "\n",
      "ğŸ”§ Äang tiá»n xá»­ lÃ½ dá»¯ liá»‡u test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1394018/1394018 [00:02<00:00, 523202.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tiá»n xá»­ lÃ½ hoÃ n táº¥t!\n",
      "\n",
      "ğŸ¯ BÆ¯á»šC 3: Dá»° ÄOÃN TRÃŠN TEST SET\n",
      "--------------------------------------------------------------------------------\n",
      "Äang dá»± Ä‘oÃ¡n...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 07:54:11.056268: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2723/2723\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step\n",
      "âœ… Dá»± Ä‘oÃ¡n hoÃ n táº¥t!\n",
      "\n",
      "ğŸ“Š BÆ¯á»šC 4: TÃNH TOÃN METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ˆ Káº¾T QUáº¢ ÄÃNH GIÃ MÃ” HÃŒNH\n",
      "================================================================================\n",
      "Accuracy:           0.9826 (98.26%)\n",
      "Precision:          0.9917 (99.17%)\n",
      "Recall:             0.9734 (97.34%)\n",
      "F1-Score:           0.9825 (98.25%)\n",
      "AUC-ROC:            0.9958\n",
      "Average Precision:  0.9969\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ CLASSIFICATION REPORT:\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Sáº¡ch (0)     0.9739    0.9918    0.9828    697009\n",
      " Äá»™c háº¡i (1)     0.9917    0.9734    0.9825    697009\n",
      "\n",
      "    accuracy                         0.9826   1394018\n",
      "   macro avg     0.9828    0.9826    0.9826   1394018\n",
      "weighted avg     0.9828    0.9826    0.9826   1394018\n",
      "\n",
      "\n",
      "âœ… ÄÃ£ lÆ°u metrics vÃ o: model_metrics.csv\n",
      "\n",
      "ğŸ¨ BÆ¯á»šC 5: Váº¼ CÃC BIá»‚U Äá»’\n",
      "--------------------------------------------------------------------------------\n",
      "âœ… ÄÃ£ lÆ°u: confusion_matrix_detailed.png\n",
      "âœ… ÄÃ£ lÆ°u: roc_curve.png\n",
      "âœ… ÄÃ£ lÆ°u: precision_recall_curve.png\n",
      "âœ… ÄÃ£ lÆ°u: score_distribution.png\n",
      "\n",
      "Äang phÃ¢n tÃ­ch threshold...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Threshold Analysis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:16<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÄÃ£ lÆ°u: threshold_analysis.png\n",
      "\n",
      "ğŸ¯ NgÆ°á»¡ng Tá»‘i Æ¯u: 0.400\n",
      "   F1-Score: 0.9826\n",
      "   Precision: 0.9893\n",
      "   Recall: 0.9759\n",
      "   Accuracy: 0.9827\n",
      "\n",
      "ğŸ” BÆ¯á»šC 6: PHÃ‚N TÃCH Lá»–I\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ“Š Thá»‘ng KÃª Chi Tiáº¿t:\n",
      "  âœ“ True Positives (TP):   678,482\n",
      "  âœ“ True Negatives (TN):   691,309\n",
      "  âœ— False Positives (FP):  5,700\n",
      "  âœ— False Negatives (FN):  18,527\n",
      "\n",
      "âŒ FALSE POSITIVES (Sáº¡ch bá»‹ nháº­n lÃ  Äá»™c háº¡i):\n",
      "   Trung bÃ¬nh score: 0.7497\n",
      "   Top 5 examples:\n",
      "   1. Score: 0.9281 | URL: integrationforall.com/sites/02%20-%20aikido/\n",
      "   2. Score: 0.5878 | URL: packetstormsecurity.nl/papers/cryptography/ssh-timing.pdf\n",
      "   3. Score: 0.9264 | URL: roblaquinta.com/wp-admin/js/login_verify2.htm\n",
      "   4. Score: 0.5071 | URL: twitter.com/TheHotOffice\n",
      "   5. Score: 0.9934 | URL: whatchadoin.com/penaltybox/\n",
      "\n",
      "âŒ FALSE NEGATIVES (Äá»™c háº¡i bá»‹ nháº­n lÃ  Sáº¡ch):\n",
      "   Trung bÃ¬nh score: 0.1347\n",
      "   Top 5 examples:\n",
      "   1. Score: 0.3224 | URL: dev.cscslacouronne.org/toutcache/x64/mimidrv.sys\n",
      "   2. Score: 0.1789 | URL: loanseed.co/qau/\n",
      "   3. Score: 0.0161 | URL: fernanda-vieira.com/\n",
      "   4. Score: 0.0554 | URL: wtctverzet.be/includes/gouv.fr-2020/pubminefi/diffusion/finances.gouv/pub/-/gouv\n",
      "   5. Score: 0.0331 | URL: cumshot-x.com/\n",
      "âœ… ÄÃ£ lÆ°u: error_boxplot.png\n",
      "\n",
      "ğŸ“Š Báº¢NG Tá»”NG Há»¢P:\n",
      "--------------------------------------------------------------------------------\n",
      "             Category   Count\n",
      "          Tá»•ng Sá»‘ Máº«u 1394018\n",
      "   URL Sáº¡ch (Thá»±c Táº¿)  697009\n",
      "URL Äá»™c Háº¡i (Thá»±c Táº¿)  697009\n",
      "       True Positives  678482\n",
      "       True Negatives  691309\n",
      "      False Positives    5700\n",
      "      False Negatives   18527\n",
      "âœ… ÄÃ£ lÆ°u: metrics_comparison.png\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ HOÃ€N THÃ€NH! Táº¤T Cáº¢ CÃC Äá»’ THá»Š ÄÃƒ ÄÆ¯á»¢C Táº O!\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Danh sÃ¡ch files Ä‘Ã£ táº¡o:\n",
      "  1. âœ… confusion_matrix_detailed.png\n",
      "  2. âœ… roc_curve.png\n",
      "  3. âœ… precision_recall_curve.png\n",
      "  4. âœ… score_distribution.png\n",
      "  5. âœ… threshold_analysis.png\n",
      "  6. âœ… error_boxplot.png\n",
      "  7. âœ… metrics_comparison.png\n",
      "  8. âœ… model_metrics.csv\n",
      "  9. âœ… evaluation_summary.csv\n",
      "\n",
      "ğŸ’¡ Sá»­ dá»¥ng cÃ¡c file PNG nÃ y Ä‘á»ƒ Ä‘Æ°a vÃ o bÃ¡o cÃ¡o LaTeX!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_curve, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD MODEL\n",
    "# ==========================================\n",
    "print(\"\\nğŸ“¦ BÆ¯á»šC 1: LOAD MODEL\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "MODEL_PATH = 'url_classifier_model.keras'  # Hoáº·c 'best_modelsaved.keras'\n",
    "\n",
    "try:\n",
    "    model = keras.models.load_model(MODEL_PATH)\n",
    "    print(f\"âœ… ÄÃ£ load model tá»«: {MODEL_PATH}\")\n",
    "    print(f\"âœ“ Model architecture:\")\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Lá»—i load model: {e}\")\n",
    "    print(\"ğŸ’¡ Kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n file model!\")\n",
    "    exit(1)\n",
    "\n",
    "# ==========================================\n",
    "# 2. LOAD VÃ€ TIá»€N Xá»¬ LÃ Dá»® LIá»†U TEST\n",
    "# ==========================================\n",
    "print(\"\\nğŸ“Š BÆ¯á»šC 2: LOAD Dá»® LIá»†U TEST\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "def preprocess_url_for_keras(url):\n",
    "    \"\"\"Tiá»n xá»­ lÃ½ URL (giá»‘ng há»‡t code train)\"\"\"\n",
    "    url = url.lower()\n",
    "    url = re.sub(r'https?://|www\\.', '', url)\n",
    "    url = url[:500]\n",
    "    url = \" \".join(list(url))\n",
    "    return url\n",
    "\n",
    "def load_data_from_txt(good_file, bad_file):\n",
    "    \"\"\"Táº£i dá»¯ liá»‡u tá»« file txt\"\"\"\n",
    "    good_urls = []\n",
    "    print(f\"\\nğŸ“ Äang Ä‘á»c {good_file}...\")\n",
    "    with open(good_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in tqdm(f, desc=\"Äá»c URL sáº¡ch\"):\n",
    "            url = line.strip()\n",
    "            if url:\n",
    "                good_urls.append(url)\n",
    "\n",
    "    bad_urls = []\n",
    "    print(f\"\\nğŸ“ Äang Ä‘á»c {bad_file}...\")\n",
    "    with open(bad_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in tqdm(f, desc=\"Äá»c URL Ä‘á»™c háº¡i\"):\n",
    "            url = line.strip()\n",
    "            if url:\n",
    "                bad_urls.append(url)\n",
    "\n",
    "    df_good = pd.DataFrame({'url': good_urls, 'label': 0})\n",
    "    df_bad = pd.DataFrame({'url': bad_urls, 'label': 1})\n",
    "    df = pd.concat([df_good, df_bad], ignore_index=True)\n",
    "    df = df.drop_duplicates(subset=['url'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df = load_data_from_txt('benign.txt', 'malicious.txt')\n",
    "    \n",
    "    # âš ï¸ QUAN TRá»ŒNG: Sort Ä‘á»ƒ Ä‘áº£m báº£o thá»© tá»± giá»‘ng code train\n",
    "    df = df.sort_values('url').reset_index(drop=True)\n",
    "    \n",
    "    # Láº¥y test set (20% cuá»‘i cÃ¹ng nhÆ° code train)\n",
    "    df_good = df[df['label'] == 0].reset_index(drop=True)\n",
    "    df_bad = df[df['label'] == 1].reset_index(drop=True)\n",
    "    \n",
    "    N_SAMPLES = min(len(df_good), len(df_bad))\n",
    "    train_val_size = int(N_SAMPLES * 0.8)\n",
    "    test_size = N_SAMPLES - train_val_size\n",
    "    \n",
    "    # Láº¥y test set\n",
    "    good_train_val = df_good.sample(n=train_val_size, random_state=42)\n",
    "    bad_train_val = df_bad.sample(n=train_val_size, random_state=42)\n",
    "    \n",
    "    good_test = df_good.drop(good_train_val.index).sample(n=test_size, random_state=42)\n",
    "    bad_test = df_bad.drop(bad_train_val.index).sample(n=test_size, random_state=42)\n",
    "    \n",
    "    df_test = pd.concat([good_test, bad_test]).sample(frac=1, random_state=42)\n",
    "    \n",
    "    print(f\"\\nâœ… ÄÃ£ load {len(df_test):,} samples test\")\n",
    "    print(f\"   - Sáº¡ch: {len(good_test):,}\")\n",
    "    print(f\"   - Äá»™c háº¡i: {len(bad_test):,}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ KhÃ´ng tÃ¬m tháº¥y file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Tiá»n xá»­ lÃ½\n",
    "print(\"\\nğŸ”§ Äang tiá»n xá»­ lÃ½ dá»¯ liá»‡u test...\")\n",
    "tqdm.pandas(desc=\"Preprocessing\")\n",
    "df_test['processed_url'] = df_test['url'].progress_apply(preprocess_url_for_keras)\n",
    "\n",
    "X_test = df_test['processed_url'].values\n",
    "y_test = df_test['label'].values.astype('float32')\n",
    "\n",
    "print(\"âœ… Tiá»n xá»­ lÃ½ hoÃ n táº¥t!\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. Dá»° ÄOÃN\n",
    "# ==========================================\n",
    "print(\"\\nğŸ¯ BÆ¯á»šC 3: Dá»° ÄOÃN TRÃŠN TEST SET\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "print(\"Äang dá»± Ä‘oÃ¡n...\")\n",
    "y_pred_proba = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "y_pred_proba = y_pred_proba.flatten()\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "print(\"âœ… Dá»± Ä‘oÃ¡n hoÃ n táº¥t!\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. TÃNH TOÃN METRICS\n",
    "# ==========================================\n",
    "print(\"\\nğŸ“Š BÆ¯á»šC 4: TÃNH TOÃN METRICS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "auc_pr = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“ˆ Káº¾T QUáº¢ ÄÃNH GIÃ MÃ” HÃŒNH\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy:           {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision:          {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"Recall:             {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:           {f1:.4f} ({f1*100:.2f}%)\")\n",
    "print(f\"AUC-ROC:            {auc_roc:.4f}\")\n",
    "print(f\"Average Precision:  {auc_pr:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nğŸ“‹ CLASSIFICATION REPORT:\")\n",
    "print(\"-\"*80)\n",
    "print(classification_report(y_test, y_pred, \n",
    "                          target_names=['Sáº¡ch (0)', 'Äá»™c háº¡i (1)'],\n",
    "                          digits=4))\n",
    "\n",
    "# LÆ°u metrics ra CSV\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC', 'Average Precision'],\n",
    "    'Value': [f\"{accuracy:.4f}\", f\"{precision:.4f}\", f\"{recall:.4f}\", \n",
    "              f\"{f1:.4f}\", f\"{auc_roc:.4f}\", f\"{auc_pr:.4f}\"]\n",
    "})\n",
    "metrics_df.to_csv('model_metrics.csv', index=False)\n",
    "print(\"\\nâœ… ÄÃ£ lÆ°u metrics vÃ o: model_metrics.csv\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. Váº¼ CONFUSION MATRIX (cáº£i tiáº¿n)\n",
    "# ==========================================\n",
    "print(\"\\nğŸ¨ BÆ¯á»šC 5: Váº¼ CÃC BIá»‚U Äá»’\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=['Sáº¡ch (Benign)', 'Äá»™c háº¡i (Malicious)'],\n",
    "            yticklabels=['Sáº¡ch (Benign)', 'Äá»™c háº¡i (Malicious)'],\n",
    "            annot_kws={'size': 16, 'weight': 'bold'})\n",
    "plt.ylabel('NhÃ£n Thá»±c Táº¿ (Actual Label)', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('NhÃ£n Dá»± ÄoÃ¡n (Predicted Label)', fontsize=13, fontweight='bold')\n",
    "plt.title('Ma Tráº­n Nháº§m Láº«n (Confusion Matrix)', fontsize=15, fontweight='bold', pad=20)\n",
    "\n",
    "# ThÃªm thÃ´ng tin thá»‘ng kÃª\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "stats_text = f'TN={tn:,}  FP={fp:,}\\nFN={fn:,}  TP={tp:,}'\n",
    "plt.text(1, -0.15, stats_text, ha='center', va='top', \n",
    "         transform=plt.gca().transAxes, fontsize=11, family='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_detailed.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… ÄÃ£ lÆ°u: confusion_matrix_detailed.png\")\n",
    "plt.close()\n",
    "\n",
    "# ==========================================\n",
    "# 6. ROC CURVE\n",
    "# ==========================================\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, linewidth=3, label=f'Model (AUC = {auc_roc:.4f})', color='darkblue')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier', alpha=0.5)\n",
    "plt.fill_between(fpr, tpr, alpha=0.2, color='blue')\n",
    "plt.xlabel('Tá»· Lá»‡ DÆ°Æ¡ng TÃ­nh Giáº£ (False Positive Rate)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Tá»· Lá»‡ DÆ°Æ¡ng TÃ­nh Tháº­t (True Positive Rate)', fontsize=12, fontweight='bold')\n",
    "plt.title('ÄÆ°á»ng Cong ROC (ROC Curve)', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=12, loc='lower right')\n",
    "plt.grid(alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… ÄÃ£ lÆ°u: roc_curve.png\")\n",
    "plt.close()\n",
    "\n",
    "# ==========================================\n",
    "# 7. PRECISION-RECALL CURVE\n",
    "# ==========================================\n",
    "precision_vals, recall_vals, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall_vals, precision_vals, linewidth=3, \n",
    "         label=f'Model (AP = {auc_pr:.4f})', color='darkgreen')\n",
    "plt.fill_between(recall_vals, precision_vals, alpha=0.2, color='green')\n",
    "plt.xlabel('Recall (Äá»™ Nháº¡y)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Precision (Äá»™ ChÃ­nh XÃ¡c)', fontsize=12, fontweight='bold')\n",
    "plt.title('ÄÆ°á»ng Cong Precision-Recall', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=12, loc='lower left')\n",
    "plt.grid(alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… ÄÃ£ lÆ°u: precision_recall_curve.png\")\n",
    "plt.close()\n",
    "\n",
    "# ==========================================\n",
    "# 8. SCORE DISTRIBUTION\n",
    "# ==========================================\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(y_pred_proba[y_test == 0], bins=60, alpha=0.65, \n",
    "         label='URL Sáº¡ch (Benign)', color='green', edgecolor='darkgreen', linewidth=1.2)\n",
    "plt.hist(y_pred_proba[y_test == 1], bins=60, alpha=0.65, \n",
    "         label='URL Äá»™c Háº¡i (Malicious)', color='red', edgecolor='darkred', linewidth=1.2)\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', linewidth=2.5, label='NgÆ°á»¡ng (Threshold = 0.5)')\n",
    "plt.xlabel('Äiá»ƒm Dá»± ÄoÃ¡n (Prediction Score)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Táº§n Sá»‘ (Frequency)', fontsize=12, fontweight='bold')\n",
    "plt.title('PhÃ¢n Bá»‘ Äiá»ƒm Dá»± ÄoÃ¡n (Score Distribution)', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=12, loc='upper center')\n",
    "plt.grid(alpha=0.3, axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('score_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… ÄÃ£ lÆ°u: score_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# ==========================================\n",
    "# 9. THRESHOLD ANALYSIS\n",
    "# ==========================================\n",
    "thresholds = np.arange(0.1, 1.0, 0.02)\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "print(\"\\nÄang phÃ¢n tÃ­ch threshold...\")\n",
    "for thresh in tqdm(thresholds, desc=\"Threshold Analysis\"):\n",
    "    y_pred_thresh = (y_pred_proba >= thresh).astype(int)\n",
    "    precisions.append(precision_score(y_test, y_pred_thresh))\n",
    "    recalls.append(recall_score(y_test, y_pred_thresh))\n",
    "    f1_scores.append(f1_score(y_test, y_pred_thresh))\n",
    "    accuracies.append(accuracy_score(y_test, y_pred_thresh))\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(thresholds, precisions, label='Precision', marker='o', markersize=4, linewidth=2)\n",
    "plt.plot(thresholds, recalls, label='Recall', marker='s', markersize=4, linewidth=2)\n",
    "plt.plot(thresholds, f1_scores, label='F1-Score', marker='^', markersize=4, linewidth=2.5)\n",
    "plt.plot(thresholds, accuracies, label='Accuracy', marker='d', markersize=4, linewidth=2, linestyle='--')\n",
    "plt.axvline(x=0.5, color='gray', linestyle='--', alpha=0.7, linewidth=2, label='Máº·c Äá»‹nh (0.5)')\n",
    "\n",
    "# TÃ¬m threshold tá»‘i Æ°u\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "plt.axvline(x=optimal_threshold, color='red', linestyle=':', linewidth=2.5, \n",
    "            label=f'Tá»‘i Æ¯u ({optimal_threshold:.2f})')\n",
    "\n",
    "plt.xlabel('NgÆ°á»¡ng PhÃ¢n Loáº¡i (Threshold)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Äiá»ƒm Sá»‘ (Score)', fontsize=12, fontweight='bold')\n",
    "plt.title('PhÃ¢n TÃ­ch NgÆ°á»¡ng (Threshold Analysis)', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=11, loc='best')\n",
    "plt.grid(alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('threshold_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… ÄÃ£ lÆ°u: threshold_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nğŸ¯ NgÆ°á»¡ng Tá»‘i Æ¯u: {optimal_threshold:.3f}\")\n",
    "print(f\"   F1-Score: {f1_scores[optimal_idx]:.4f}\")\n",
    "print(f\"   Precision: {precisions[optimal_idx]:.4f}\")\n",
    "print(f\"   Recall: {recalls[optimal_idx]:.4f}\")\n",
    "print(f\"   Accuracy: {accuracies[optimal_idx]:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 10. ERROR ANALYSIS\n",
    "# ==========================================\n",
    "print(\"\\nğŸ” BÆ¯á»šC 6: PHÃ‚N TÃCH Lá»–I\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "fp_indices = np.where((y_pred == 1) & (y_test == 0))[0]\n",
    "fn_indices = np.where((y_pred == 0) & (y_test == 1))[0]\n",
    "tp_indices = np.where((y_pred == 1) & (y_test == 1))[0]\n",
    "tn_indices = np.where((y_pred == 0) & (y_test == 0))[0]\n",
    "\n",
    "print(f\"\\nğŸ“Š Thá»‘ng KÃª Chi Tiáº¿t:\")\n",
    "print(f\"  âœ“ True Positives (TP):   {len(tp_indices):,}\")\n",
    "print(f\"  âœ“ True Negatives (TN):   {len(tn_indices):,}\")\n",
    "print(f\"  âœ— False Positives (FP):  {len(fp_indices):,}\")\n",
    "print(f\"  âœ— False Negatives (FN):  {len(fn_indices):,}\")\n",
    "\n",
    "if len(fp_indices) > 0:\n",
    "    print(f\"\\nâŒ FALSE POSITIVES (Sáº¡ch bá»‹ nháº­n lÃ  Äá»™c háº¡i):\")\n",
    "    print(f\"   Trung bÃ¬nh score: {y_pred_proba[fp_indices].mean():.4f}\")\n",
    "    print(f\"   Top 5 examples:\")\n",
    "    for i, idx in enumerate(fp_indices[:5], 1):\n",
    "        print(f\"   {i}. Score: {y_pred_proba[idx]:.4f} | URL: {df_test.iloc[idx]['url'][:80]}\")\n",
    "\n",
    "if len(fn_indices) > 0:\n",
    "    print(f\"\\nâŒ FALSE NEGATIVES (Äá»™c háº¡i bá»‹ nháº­n lÃ  Sáº¡ch):\")\n",
    "    print(f\"   Trung bÃ¬nh score: {y_pred_proba[fn_indices].mean():.4f}\")\n",
    "    print(f\"   Top 5 examples:\")\n",
    "    for i, idx in enumerate(fn_indices[:5], 1):\n",
    "        print(f\"   {i}. Score: {y_pred_proba[idx]:.4f} | URL: {df_test.iloc[idx]['url'][:80]}\")\n",
    "\n",
    "# ==========================================\n",
    "# 11. BOXPLOT ERROR ANALYSIS\n",
    "# ==========================================\n",
    "error_data = {\n",
    "    'True\\nPositive': y_pred_proba[tp_indices] if len(tp_indices) > 0 else [],\n",
    "    'True\\nNegative': y_pred_proba[tn_indices] if len(tn_indices) > 0 else [],\n",
    "    'False\\nPositive': y_pred_proba[fp_indices] if len(fp_indices) > 0 else [],\n",
    "    'False\\nNegative': y_pred_proba[fn_indices] if len(fn_indices) > 0 else []\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "box_parts = plt.boxplot([v for v in error_data.values() if len(v) > 0], \n",
    "                        labels=[k for k, v in error_data.items() if len(v) > 0],\n",
    "                        patch_artist=True,\n",
    "                        notch=True,\n",
    "                        showmeans=True)\n",
    "\n",
    "# TÃ´ mÃ u\n",
    "colors = ['lightgreen', 'lightblue', 'lightcoral', 'lightyellow']\n",
    "for patch, color in zip(box_parts['boxes'], colors[:len(box_parts['boxes'])]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', linewidth=2, label='NgÆ°á»¡ng (0.5)', alpha=0.7)\n",
    "plt.ylabel('Äiá»ƒm Dá»± ÄoÃ¡n (Prediction Score)', fontsize=12, fontweight='bold')\n",
    "plt.title('PhÃ¢n Bá»‘ Äiá»ƒm Theo Loáº¡i Dá»± ÄoÃ¡n (Score Distribution by Prediction Type)', \n",
    "          fontsize=15, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3, axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('error_boxplot.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… ÄÃ£ lÆ°u: error_boxplot.png\")\n",
    "plt.close()\n",
    "\n",
    "# ==========================================\n",
    "# 12. SUMMARY TABLE\n",
    "# ==========================================\n",
    "summary_data = {\n",
    "    'Category': ['Tá»•ng Sá»‘ Máº«u', 'URL Sáº¡ch (Thá»±c Táº¿)', 'URL Äá»™c Háº¡i (Thá»±c Táº¿)', \n",
    "                 'True Positives', 'True Negatives', \n",
    "                 'False Positives', 'False Negatives'],\n",
    "    'Count': [len(y_test), \n",
    "              int(np.sum(y_test == 0)), \n",
    "              int(np.sum(y_test == 1)),\n",
    "              len(tp_indices),\n",
    "              len(tn_indices),\n",
    "              len(fp_indices),\n",
    "              len(fn_indices)]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv('evaluation_summary.csv', index=False)\n",
    "\n",
    "print(\"\\nğŸ“Š Báº¢NG Tá»”NG Há»¢P:\")\n",
    "print(\"-\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# 13. Táº O BIá»‚U Äá»’ SO SÃNH METRICS\n",
    "# ==========================================\n",
    "metrics_comparison = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'Score': [accuracy, precision, recall, f1]\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(metrics_comparison['Metric'], metrics_comparison['Score'], \n",
    "               color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'],\n",
    "               alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# ThÃªm giÃ¡ trá»‹ trÃªn má»—i cá»™t\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.4f}\\n({height*100:.2f}%)',\n",
    "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.ylabel('Score', fontsize=12, fontweight='bold')\n",
    "plt.title('So SÃ¡nh CÃ¡c Metrics ÄÃ¡nh GiÃ¡', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(alpha=0.3, axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… ÄÃ£ lÆ°u: metrics_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "# ==========================================\n",
    "# HOÃ€N THÃ€NH\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ‰ HOÃ€N THÃ€NH! Táº¤T Cáº¢ CÃC Äá»’ THá»Š ÄÃƒ ÄÆ¯á»¢C Táº O!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nğŸ“ Danh sÃ¡ch files Ä‘Ã£ táº¡o:\")\n",
    "print(\"  1. âœ… confusion_matrix_detailed.png\")\n",
    "print(\"  2. âœ… roc_curve.png\")\n",
    "print(\"  3. âœ… precision_recall_curve.png\")\n",
    "print(\"  4. âœ… score_distribution.png\")\n",
    "print(\"  5. âœ… threshold_analysis.png\")\n",
    "print(\"  6. âœ… error_boxplot.png\")\n",
    "print(\"  7. âœ… metrics_comparison.png\")\n",
    "print(\"  8. âœ… model_metrics.csv\")\n",
    "print(\"  9. âœ… evaluation_summary.csv\")\n",
    "print(\"\\nğŸ’¡ Sá»­ dá»¥ng cÃ¡c file PNG nÃ y Ä‘á»ƒ Ä‘Æ°a vÃ o bÃ¡o cÃ¡o LaTeX!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
